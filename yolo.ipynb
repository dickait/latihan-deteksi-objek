{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAW Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "basepath = os.getcwd()\n",
    "print(f\"Current directory path: {basepath}\")\n",
    "\n",
    "# Change the directory to the dataset folder\n",
    "data_folder = os.path.join(basepath, \"kaggle-satellite-imagery/shipsnet/shipsnet\")\n",
    "print(f\"Data folder path: {data_folder}\")\n",
    "\n",
    "# Generate a list of files for ship and no_ship files\n",
    "files_list_no_ship = glob(os.path.join(data_folder, \"0_*\"))\n",
    "files_list_ship = glob(os.path.join(data_folder, \"1_*\"))\n",
    "\n",
    "# Verify files are loaded\n",
    "print(f\"No-ship files: {len(files_list_no_ship)}, Ship files: {len(files_list_ship)}\")\n",
    "\n",
    "# Initialize image and label arrays\n",
    "images = []\n",
    "labels = []\n",
    "text_labels = ['No ship', 'Ship']\n",
    "\n",
    "# Load no-ship images\n",
    "for file in files_list_no_ship:\n",
    "    img = cv2.imread(file)\n",
    "    if img is not None:  # Check if image is loaded properly\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        images.append(img)\n",
    "        labels.append(0)\n",
    "\n",
    "# Load ship images\n",
    "for file in files_list_ship:\n",
    "    img = cv2.imread(file)\n",
    "    if img is not None:  # Check if image is loaded properly\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        images.append(img)\n",
    "        labels.append(1)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "images = np.array(images, dtype=np.int64)\n",
    "labels = np.array(labels, dtype=np.int64)\n",
    "\n",
    "# Verify dataset size\n",
    "print(f\"Total images: {len(images)}, Total labels: {len(labels)}\")\n",
    "\n",
    "# Split the data into train (70%), validation (20%), and test (10%) datasets\n",
    "np.random.seed(27)\n",
    "indices = np.arange(len(images))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "images = images[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "train = int(0.7 * len(images))\n",
    "validation = int(0.2 * len(images))\n",
    "test = len(images) - (train + validation)\n",
    "\n",
    "X_train, y_train = images[:train], labels[:train]\n",
    "X_validation, y_validation = images[train:(train + validation)], labels[train:(train + validation)]\n",
    "X_test, y_test = images[(train + validation):], labels[(train + validation):]\n",
    "\n",
    "# Ensure the split is correct\n",
    "print(f\"Train: {len(X_train)}, Validation: {len(X_validation)}, Test: {len(X_test)}\")\n",
    "\n",
    "# One-hot encode the labels\n",
    "n_classes = 2\n",
    "y_train = to_categorical(y_train, n_classes)\n",
    "y_validation = to_categorical(y_validation, n_classes)\n",
    "y_test = to_categorical(y_test, n_classes)\n",
    "\n",
    "# Plot some sample images\n",
    "if len(X_train) > 0:\n",
    "    n_rows = 3\n",
    "    n_cols = 5\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i in range(n_rows * n_cols):\n",
    "        ax = plt.subplot(n_rows, n_cols, i + 1)\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticklabels([])\n",
    "        index = random.randint(0, len(X_train) - 1)\n",
    "        plt.imshow(X_train[index])\n",
    "        plt.title(text_labels[np.argmax(y_train[index])])\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Training dataset is empty. Please check dataset loading and splitting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation for Classify YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from datetime import datetime\n",
    "\n",
    "# def prepare_yolo_dataset(X_train, y_train, X_validation, y_validation, X_test, y_test):\n",
    "#     \"\"\"\n",
    "#     Prepares a dataset directory structure for YOLO classification.\n",
    "\n",
    "#     Args:\n",
    "#         X_train (numpy.ndarray): Training images.\n",
    "#         y_train (numpy.ndarray): Training labels (one-hot encoded).\n",
    "#         X_validation (numpy.ndarray): Validation images.\n",
    "#         y_validation (numpy.ndarray): Validation labels (one-hot encoded).\n",
    "#         X_test (numpy.ndarray): Test images.\n",
    "#         y_test (numpy.ndarray): Test labels (one-hot encoded).\n",
    "    \n",
    "#     Returns:\n",
    "#         str: Path to the YOLO dataset directory.\n",
    "#     \"\"\"\n",
    "#     # Base directory for organizing the dataset\n",
    "#     base_dir = \"YOLO\"\n",
    "\n",
    "#     # Generate a timestamp for the folder name\n",
    "#     timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#     yolo_dir = os.path.join(base_dir, timestamp)\n",
    "\n",
    "#     # Create subdirectories for YOLO\n",
    "#     train_dir = os.path.join(yolo_dir, \"train\")\n",
    "#     val_dir = os.path.join(yolo_dir, \"val\")\n",
    "#     test_dir = os.path.join(yolo_dir, \"test\")\n",
    "\n",
    "#     # Subfolders for classes within train, val, and test\n",
    "#     os.makedirs(os.path.join(train_dir, \"0\"), exist_ok=True)\n",
    "#     os.makedirs(os.path.join(train_dir, \"1\"), exist_ok=True)\n",
    "#     os.makedirs(os.path.join(val_dir, \"0\"), exist_ok=True)\n",
    "#     os.makedirs(os.path.join(val_dir, \"1\"), exist_ok=True)\n",
    "#     os.makedirs(os.path.join(test_dir, \"0\"), exist_ok=True)\n",
    "#     os.makedirs(os.path.join(test_dir, \"1\"), exist_ok=True)\n",
    "\n",
    "#     # Helper function to save images\n",
    "#     def save_images(images, labels, output_subdir):\n",
    "#         for i, (img, label) in enumerate(zip(images, labels)):\n",
    "#             class_dir = os.path.join(output_subdir, str(label))\n",
    "#             filename = f\"img_{i}.jpg\"\n",
    "#             filepath = os.path.join(class_dir, filename)\n",
    "            \n",
    "#             # Convert image to uint8 format\n",
    "#             if img.dtype != np.uint8:\n",
    "#                 img = np.clip(img, 0, 255)  # Ensure pixel values are within range\n",
    "#                 img = img.astype(np.uint8)\n",
    "            \n",
    "#             # Save the image\n",
    "#             cv2.imwrite(filepath, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "#     # Save train, validation, and test datasets\n",
    "#     save_images(X_train, np.argmax(y_train, axis=1), train_dir)\n",
    "#     save_images(X_validation, np.argmax(y_validation, axis=1), val_dir)\n",
    "#     save_images(X_test, np.argmax(y_test, axis=1), test_dir)\n",
    "\n",
    "#     # Create the YOLO data.yaml file\n",
    "#     yaml_content = f\"\"\"\n",
    "#     path: {yolo_dir}\n",
    "#     train: {os.path.abspath(train_dir)}\n",
    "#     val: {os.path.abspath(val_dir)}\n",
    "#     test: {os.path.abspath(test_dir)}\n",
    "#     nc: 2\n",
    "#     names:\n",
    "#       0: No Ship\n",
    "#       1: Ship\n",
    "#     \"\"\"\n",
    "\n",
    "#     yaml_path = os.path.join(yolo_dir, \"data.yaml\")\n",
    "#     with open(yaml_path, \"w\") as yaml_file:\n",
    "#         yaml_file.write(yaml_content)\n",
    "\n",
    "#     print(f\"Dataset and YOLO configuration created successfully in: {yolo_dir}\")\n",
    "#     return yolo_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation for Object Detection YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def prepare_yolo_dataset(X_train, y_train, X_validation, y_validation, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Prepares a dataset directory structure for YOLO detection.\n",
    "\n",
    "    Args:\n",
    "        X_train (numpy.ndarray): Training images.\n",
    "        y_train (numpy.ndarray): Training labels (one-hot encoded).\n",
    "        X_validation (numpy.ndarray): Validation images.\n",
    "        y_validation (numpy.ndarray): Validation labels (one-hot encoded).\n",
    "        X_test (numpy.ndarray): Test images.\n",
    "        y_test (numpy.ndarray): Test labels (one-hot encoded).\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the YOLO dataset directory.\n",
    "    \"\"\"\n",
    "    # Base directory for organizing the dataset\n",
    "    base_dir = \"YOLO\"\n",
    "\n",
    "    # Generate a timestamp for the folder name\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    yolo_dir = os.path.join(base_dir, timestamp)\n",
    "\n",
    "    # Create subdirectories for YOLO\n",
    "    train_dir = os.path.join(yolo_dir, \"train/images\")\n",
    "    val_dir = os.path.join(yolo_dir, \"val/images\")\n",
    "    test_dir = os.path.join(yolo_dir, \"test/images\")\n",
    "    train_labels_dir = os.path.join(yolo_dir, \"train/labels\")\n",
    "    val_labels_dir = os.path.join(yolo_dir, \"val/labels\")\n",
    "    test_labels_dir = os.path.join(yolo_dir, \"test/labels\")\n",
    "\n",
    "    # Create directories for images and labels\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(val_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    os.makedirs(train_labels_dir, exist_ok=True)\n",
    "    os.makedirs(val_labels_dir, exist_ok=True)\n",
    "    os.makedirs(test_labels_dir, exist_ok=True)\n",
    "\n",
    "    # Helper function to save images and labels\n",
    "    def save_images_and_labels(images, labels, image_output_dir, label_output_dir):\n",
    "        for i, (img, label) in enumerate(zip(images, labels)):\n",
    "            # Save image\n",
    "            image_filename = f\"img_{i}.jpg\"\n",
    "            image_filepath = os.path.join(image_output_dir, image_filename)\n",
    "            \n",
    "            # Convert image to uint8 format\n",
    "            if img.dtype != np.uint8:\n",
    "                img = np.clip(img, 0, 255)  # Ensure pixel values are within range\n",
    "                img = img.astype(np.uint8)\n",
    "            \n",
    "            # Save the image\n",
    "            cv2.imwrite(image_filepath, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "            # Save label\n",
    "            label_filename = f\"img_{i}.txt\"\n",
    "            label_filepath = os.path.join(label_output_dir, label_filename)\n",
    "            with open(label_filepath, \"w\") as label_file:\n",
    "                if np.argmax(label) == 1:  # Only create bounding box for images with ships\n",
    "                    # Class 1 (Ship), bbox centered at (0.5, 0.5) with width and height of 1 (entire image)\n",
    "                    label_file.write(\"1 0.5 0.5 1 1\\n\")\n",
    "\n",
    "    # Save train, validation, and test datasets\n",
    "    save_images_and_labels(X_train, y_train, train_dir, train_labels_dir)\n",
    "    save_images_and_labels(X_validation, y_validation, val_dir, val_labels_dir)\n",
    "    save_images_and_labels(X_test, y_test, test_dir, test_labels_dir)\n",
    "\n",
    "    # Create the YOLO data.yaml file\n",
    "    yaml_content = f\"\"\"\n",
    "    path: {yolo_dir}\n",
    "    train: {os.path.abspath(train_dir)}\n",
    "    val: {os.path.abspath(val_dir)}\n",
    "    test: {os.path.abspath(test_dir)}\n",
    "    nc: 2\n",
    "    names:\n",
    "      0: No Ship\n",
    "      1: Ship\n",
    "    \"\"\"\n",
    "\n",
    "    yaml_path = os.path.join(yolo_dir, \"data.yaml\")\n",
    "    with open(yaml_path, \"w\") as yaml_file:\n",
    "        yaml_file.write(yaml_content)\n",
    "\n",
    "    print(f\"Dataset and YOLO configuration created successfully in: {yolo_dir}\")\n",
    "    return yolo_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create YOLO MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yolov8(model_type='yolov8n.pt', input_shape=(80, 80), n_classes=2):\n",
    "    \"\"\"\n",
    "    Creates a YOLOv8 classification model.\n",
    "    \n",
    "    :param model_type: The type of YOLOv8 model (e.g., yolov8n-cls, yolov8s-cls, etc.)\n",
    "    :param input_shape: The input shape of images (height, width).\n",
    "    :param n_classes: Number of classes for classification.\n",
    "    :return: Trained YOLO model ready for further use or training.\n",
    "    \"\"\"\n",
    "    # Initialize the model\n",
    "    model = YOLO(model_type)\n",
    "\n",
    "    # Configure the model for the dataset\n",
    "    model.model.input_size = input_shape\n",
    "    model.model.nc = n_classes  # Number of classes\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data and Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_dataset_path = prepare_yolo_dataset(X_train, y_train, X_validation, y_validation, X_test, y_test)\n",
    "\n",
    "# Initialize the YOLOv8 classification model\n",
    "model = create_yolov8(model_type='yolov8n.pt', input_shape=(80, 80), n_classes=2)\n",
    "print(f\"Dataset prepared at: {yolo_dataset_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data using information from data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train YOLOv8 using the dataset\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "the_folder = os.path.join(current_dir, yolo_dataset_path)\n",
    "print(f\"Current directory: {the_folder}\")\n",
    "\n",
    "yaml_data = os.path.join(the_folder, \"data.yaml\")\n",
    "print(f\"Data.yaml path: {yaml_data}\")\n",
    "\n",
    "# Train the model with verbose logging enabled\n",
    "model.train(\n",
    "    data=yaml_data,  # Path to the dataset's data.yaml\n",
    "    epochs=3,         # Number of epochs\n",
    "    batch=8,          # Image size\n",
    "    imgsz=96,         # Batch size\n",
    "    project=the_folder,  # Specify the folder to save the training results\n",
    "    name=\"train_results\",  # Subdirectory name under 'the_folder'\n",
    "    verbose=True,\n",
    "    patience=5,\n",
    ")\n",
    "print(\"YOLOv8 training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Images from Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference on the test dataset defined in 'data.yaml'\n",
    "results = model.predict(source=os.path.join(the_folder, 'test/images'), save=True, save_txt=True)\n",
    "\n",
    "# Print the results (you can inspect each predicted image and bounding box information)\n",
    "print(\"Predictions completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting predicted images randomly\n",
    "from save directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_results = results[-1]  # Get the latest results\n",
    "# Print the results (you can inspect each predicted image and bounding box information)\n",
    "print(\"Predictions completed.\")\n",
    "save_dir = latest_results.save_dir\n",
    "print(f\"Save directory: {save_dir}\")\n",
    "\n",
    "images = []\n",
    "\n",
    "# Load the predicted images from the save directory\n",
    "for img_name in os.listdir(save_dir):\n",
    "    if img_name.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        img_path = os.path.join(save_dir, img_name)\n",
    "        images.append(cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB))\n",
    "\n",
    "# Randomly select 25 images for visualization\n",
    "indices = random.sample(range(len(images)), min(25, len(images)))\n",
    "\n",
    "# Plot 25 images, 5 rows, 5 columns, without labels\n",
    "n_rows, n_cols = 5, 5\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i, idx in enumerate(indices):\n",
    "    ax = plt.subplot(n_rows, n_cols, i + 1)\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    plt.imshow(images[idx])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting predictions and true labels for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting predictions and true labels for visualization\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "images = []\n",
    "\n",
    "# Load the predictions and true labels\n",
    "for result in results:\n",
    "    img_path = result.path\n",
    "    images.append(cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # Extract true label from corresponding label file in 'test/labels'\n",
    "    label_path = img_path.replace('images', 'labels').replace('.jpg', '.txt')\n",
    "    with open(label_path, 'r') as label_file:\n",
    "        label_content = label_file.read().strip()\n",
    "        if label_content:\n",
    "            true_label = 1 if label_content.startswith('1') else 0\n",
    "        else:\n",
    "            true_label = 0\n",
    "    true_labels.append(true_label)\n",
    "    \n",
    "    # Get predicted label\n",
    "    if len(result.boxes) > 0:  # If at least one box is predicted, it's classified as 'Ship'\n",
    "        predicted_labels.append(1)\n",
    "    else:\n",
    "        predicted_labels.append(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting predicted images with label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Randomly select 15 images for visualization\n",
    "indices = random.sample(range(len(images)), min(15, len(images)))\n",
    "\n",
    "# Plot 15 images, 3 rows, 5 columns, showing predictions vs. true labels\n",
    "n_rows, n_cols = 3, 5\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, idx in enumerate(indices):\n",
    "    ax = plt.subplot(n_rows, n_cols, i + 1)\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    plt.imshow(images[idx])\n",
    "    true_label = 'Ship' if true_labels[idx] == 1 else 'No Ship'\n",
    "    predicted_label = 'Ship' if predicted_labels[idx] == 1 else 'No Ship'\n",
    "    plt.title(f\"True: {true_label}\\nPred: {predicted_label}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to use the model for real scene but not working XD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle_data = os.path.join(basepath, \"kaggle-satellite-imagery/scenes/scenes/lb_3.png\")\n",
    "kaggle_data = os.path.join(basepath, \"kaggle-satellite-imagery/scenes/scenes\")\n",
    "print(f\"Kaggle data folder path: {kaggle_data}\")\n",
    "\n",
    "# Perform inference on the test dataset defined in 'data.yaml'\n",
    "results = model.predict(source=kaggle_data, imgsz=1024)\n",
    "print(results)\n",
    "\n",
    "# Display the result\n",
    "# Load the image with detections\n",
    "img = cv2.imread(kaggle_data)\n",
    "for result in results:\n",
    "    for box in result.boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0]  # Get bounding box coordinates\n",
    "        confidence = box.conf  # Confidence score\n",
    "        class_id = int(box.cls)  # Class ID\n",
    "\n",
    "        # Draw the bounding box\n",
    "        label = f\"Ship ({confidence.item():.2f})\" if class_id == 1 else f\"Not Ship ({confidence.item():.2f})\"\n",
    "        color = (0, 255, 0) if class_id == 1 else (255, 0, 0)  # Green for ship, red otherwise\n",
    "        cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "        cv2.putText(img, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "# Convert image to RGB (for displaying in matplotlib)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Plot the image with the detected bounding boxes\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(img_rgb)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to use another model manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained YOLO model\n",
    "model_test = YOLO('D:\\\\program\\\\object-detection\\\\YOLO\\\\20241119_042947\\\\train_results\\\\weights\\\\best.pt')  # Replace with the path to your trained model\n",
    "\n",
    "# Path to the image you want to perform inference on\n",
    "kaggle_data = os.path.join(basepath, \"kaggle-satellite-imagery/scenes/scenes\")\n",
    "\n",
    "# Perform inference on the image\n",
    "results_test = model_test.predict(source=kaggle_data, imgsz=1024)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
